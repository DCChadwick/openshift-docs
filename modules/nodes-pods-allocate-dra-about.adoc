// Module included in the following assemblies:
//
// * nodes/nodes-pods-allocate-dra.adoc

:_mod-docs-content-type: CONCEPT
[id="nodes-pods-allocate-dra-about_{context}"]
= About allocating GPUs to workloads

// Taken from https://issues.redhat.com/browse/OCPSTRAT-1756
{attribute-based-full} enables pods to request graphics processing units (GPU) based on specific device attributes. This ensures that each pod receives the exact GPU specifications it requires.

// Hiding until GA. The driver is not integrated in the TP version. 
// With the NVIDIA Kubernetes DRA driver integrated into OpenShift,by the NVIDIA GPU Operator with a DRA driver

Attribute-based resource allocation requires that you install a Dynamic Resource Allocation (DRA) driver. A DRA driver is a third-party application that runs on each node in your cluster to interface with the hardware of that node. 

The DRA driver advertises several GPU device attributes that {product-title} can use for precise GPU selection, including the following attributes:

Product Name::
Pods can request an exact GPU model based on performance requirements or compatibility with applications. This ensures that workloads leverage the best-suited hardware for their tasks.

GPU Memory Capacity::
Pods can request GPUs with a minimum or maximum memory capacity, such as 8 GB, 16 GB, or 40 GB. This is helpful with memory-intensive workloads such as large AI model training or data processing. This attribute enables applications to allocate GPUs that meet memory needs without overcommitting or underutilizing resources.

Compute Capability::
Pods can request GPUs based on the compute capabilities of the GPU, such as the CUDA versions supported. Pods can target GPUs that are compatible with the applicationâ€™s framework and leverage optimized processing capabilities.

Power and Thermal Profiles:: 
Pods can request GPUs based on power usage or thermal characteristics, enabling power-sensitive or temperature-sensitive applications to operate efficiently. This is particularly useful in high-density environments where energy or cooling constraints are factors.

Device ID and Vendor ID:: 
Pods can request GPUs based on the GPU's hardware specifics, which allows applications that require specific vendors or device types to make targeted requests.

Driver Version:: 
Pods can request GPUs that run a specific driver version, ensuring compatibility with application dependencies and maximizing GPU feature access.
